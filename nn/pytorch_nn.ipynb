{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mnist_reader import load_mnist_df,show_mnist_image\n",
    "\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepping the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = load_mnist_df('../data/')\n",
    "test_df = load_mnist_df('../data/', test = True)\n",
    "show_mnist_image(train_df,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_df.drop('label', axis=1).astype('int8'))\n",
    "X_train = X_train.astype('float32')/255\n",
    "y_train = np.array(train_df.label)\n",
    "\n",
    "X_test = np.array(test_df.drop('label', axis=1).astype('int8'))\n",
    "X_test = X_test.astype('float32')/255\n",
    "y_test = np.array(test_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(X_train.shape[0]*0.7)\n",
    "\n",
    "X_train, X_val = X_train[:split_size], X_train[split_size:]\n",
    "y_train, y_val = y_train[:split_size], y_train[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.num_features = 28*28\n",
    "        self.output_num_units = 10 #number of classes\n",
    "\n",
    "        self.hidden_layer0 = torch.nn.Sequential(torch.nn.Linear(self.num_features, 392),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Dropout(p=0.2))\n",
    "        self.hidden_layer1 = torch.nn.Sequential(torch.nn.Linear(392, 392),\n",
    "                        torch.nn.LeakyReLU(),\n",
    "                        torch.nn.Dropout(p=0.2))\n",
    "        self.out_layer = torch.nn.Linear(392, self.output_num_units)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer0(x)\n",
    "        x = self.hidden_layer1(x)\n",
    "        x = self.out_layer(x)\n",
    "        return(x)\n",
    "\n",
    "model = model()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set remaining variables\n",
    "epochs = 64\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002 \n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimization algorithm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "# preprocess a batch of dataset\n",
    "def preproc(unclean_batch_x):\n",
    "  \"\"\"Convert values to range 0-1\"\"\"\n",
    "  temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    " \n",
    "  return temp_batch\n",
    "\n",
    "# create a batch\n",
    "def batch_creator(X_train, y_train, batch_size):\n",
    "  dataset_length = X_train.shape[0]\n",
    "  \n",
    "  batch_mask = rng.choice(dataset_length, batch_size)\n",
    "  \n",
    "  batch_x = X_train[batch_mask]\n",
    "  batch_x = preproc(batch_x)\n",
    "  \n",
    "  batch_y = y_train[batch_mask]\n",
    "  \n",
    "  return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7660476190476191 0.5325\n",
      "1 0.7490476190476191 0.5306666666666666\n",
      "2 0.7468571428571429 0.5286111111111111\n",
      "3 0.7630238095238095 0.5343888888888889\n",
      "4 0.735904761904762 0.5151666666666667\n",
      "5 0.7665952380952381 0.5351666666666667\n",
      "6 0.78 0.5458888888888889\n",
      "7 0.7579047619047619 0.5262777777777777\n",
      "8 0.7816904761904762 0.5493333333333333\n",
      "9 0.7783809523809524 0.5474444444444444\n",
      "10 0.7745 0.537\n",
      "11 0.7485 0.5271111111111111\n",
      "12 0.7806666666666666 0.5357222222222222\n",
      "13 0.7668809523809523 0.5412777777777777\n",
      "14 0.7716666666666666 0.5399444444444444\n",
      "15 0.763452380952381 0.5323888888888889\n",
      "16 0.7588571428571429 0.5346666666666666\n",
      "17 0.7653809523809524 0.5445555555555556\n",
      "18 0.7689285714285714 0.5335\n",
      "19 0.7968809523809524 0.5456111111111112\n",
      "20 0.7688571428571429 0.5433333333333333\n",
      "21 0.7816428571428572 0.5391111111111111\n",
      "22 0.7743571428571429 0.5396111111111112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e71036484191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# create batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# pass that batch for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-07a96f85508b>\u001b[0m in \u001b[0;36mbatch_creator\u001b[0;34m(X_train, y_train, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mbatch_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train network\n",
    "total_batch = int(X_train.shape[0]/batch_size)\n",
    "\n",
    "epoch_list,epoch_train_accuracies,epoch_val_accuracies = [],[],[]\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        # create batches\n",
    "        batch_x, batch_y = batch_creator(X_train,y_train,batch_size)\n",
    "\n",
    "        # pass that batch for training\n",
    "        x, y = Variable(torch.from_numpy(batch_x)), Variable(torch.from_numpy(batch_y), requires_grad=False)\n",
    "        pred = model(x)\n",
    "\n",
    "        # get loss\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # perform backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    x = Variable(torch.from_numpy(preproc(X_train)))\n",
    "    pred_train = model(x)\n",
    "    final_pred = np.argmax(pred_train.data.numpy(), axis=1)\n",
    "    epoch_train_accuracy = accuracy_score(y_train, final_pred)\n",
    "  \n",
    "    x = Variable(torch.from_numpy(preproc(X_val)))\n",
    "    pred_val = model(x)\n",
    "    final_pred = np.argmax(pred_val.data.numpy(), axis=1)\n",
    "    epoch_val_accuracy = accuracy_score(y_val, final_pred)\n",
    "    \n",
    "    epoch_list.append(epoch)\n",
    "    epoch_train_accuracies.append(epoch_train_accuracy)\n",
    "    epoch_val_accuracies.append(epoch_val_accuracy)\n",
    "    \n",
    "    print(epoch, epoch_train_accuracy, epoch_val_accuracy)\n",
    "    \n",
    "plt.plot(epoch_list,epoch_train_accuracies,epoch_val_accuracies) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.model'>: it's not the same object as __main__.model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3fd2b1c2bcd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\"./model_20190718\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.model'>: it's not the same object as __main__.model"
     ]
    }
   ],
   "source": [
    "model_save = model\n",
    "torch.save(model_save ,\"./model_20190718\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20607142857142857"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing set accuracy\n",
    "x, y = Variable(torch.from_numpy(preproc(X_train))), Variable(torch.from_numpy(y_train), requires_grad=False)\n",
    "pred = model(x)\n",
    "\n",
    "final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "accuracy_score(y_train, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1995"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get validation accuracy\n",
    "x, y = Variable(torch.from_numpy(preproc(X_val))), Variable(torch.from_numpy(y_val), requires_grad=False)\n",
    "pred = model(x)\n",
    "final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "accuracy_score(y_val, final_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network predicts  3 this is  False\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "viewing specific test cases\n",
    "\"\"\"\n",
    "test_index = np.random.randint(0,len(X_test))\n",
    "x = Variable(torch.from_numpy(preproc(X_test[test_index])))\n",
    "pred = model(x)\n",
    "final_pred = np.argmax(pred.data.numpy())\n",
    "\n",
    "print('neural network predicts ', final_pred,'this is ', final_pred == y_test[test_index])\n",
    "show_mnist_image(test_df, index = test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
